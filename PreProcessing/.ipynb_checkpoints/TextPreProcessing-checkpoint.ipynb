{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PREPROCESSING\n",
    "#### Input File: \"Input_1.txt\"\n",
    "\n",
    "1)Create a text file with, at least, 200 words in it and items that challenge the tokeniser (e.g., I.B.M., and such like\n",
    "things). But, you need to make these up yourself, so you think about what it is doing.\n",
    "    \n",
    "    a. Load the file in and use nltk.word_tokenizer() on it. Report the list of tokens that are produced from it and note any oddities that arise. Comment on these oddities and how they might be handled.\n",
    "    \n",
    "    b. Now, take the output from normalization and run it through the postagger.\n",
    "    \n",
    "    c. Now, take the output from normalization step and run it through a postagger. Report this output as your answer and highlight any inaccuracies that occur at this stage.\n",
    "\n",
    "## STEP 1: TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Ms. Simmy, Following is a narrative story of a girly girl named as KATY. Working as a \"Jr. Consultant\" with TIBCO Software Inc., in the field of Integration along with TIBCO ActiveMatrix BusinessWorks, TIBCO Spotfire proved to be a great experience to me as I had the privilege to deal with most complex business application, i.e. Middleware.I developed a reusable component that enables the associates in the organization; to go through at self-paced training and learning on end to end integration for performing data validation using numerous SOA products like TIBCO ActiveMatrix Business Works 6 integrating and orchestrating the applications flows, Clarity for data cleansing, M.D.M. for the data versioning, data storage and TIBCO Spotfire applies to Machine Learning. I was exposed to the opportunity of problem solving and logicaally analyzing them and implement the complex business scenarios.I found that Ireland is one of the fastest growing tech sector and known as the \"Silicon Valley of Europe”. It has been ranked No. 1 for Research by Times Higher Education \\'16. It is one of Europe\\'s leading research-intensive universities; an environment where undergrads edu, masters and PhD training, research, innovation and community enrisent form a dynamic spectrum of activity. The strek of research and innovation at U.C.D., Ireland embraces scholars, research groups and collaborations with industry and other technology partners. Her eagerness to learn machinery saw her undertake various programming language courses and certifications like Linux Boot camp, Python, Core Java, .Net: C Sharp(C#) by Microsoft Academy. She even presented a seminar fasting on ‘Prevention of Rogue Access Point using Device Fingerprinting in Wireless Network’. Thanks for your support bdw.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_handle = open(r\"Input_1.txt\",\"r\", encoding=\"utf8\")\n",
    "inputFile= file_handle.read()\n",
    "inputFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'Ms.',\n",
       " 'Simmy',\n",
       " ',',\n",
       " 'Following',\n",
       " 'is',\n",
       " 'a',\n",
       " 'narrative',\n",
       " 'story',\n",
       " 'of',\n",
       " 'a',\n",
       " 'girly',\n",
       " 'girl',\n",
       " 'named',\n",
       " 'as',\n",
       " 'KATY',\n",
       " '.',\n",
       " 'Working',\n",
       " 'as',\n",
       " 'a',\n",
       " '``',\n",
       " 'Jr',\n",
       " '.',\n",
       " 'Consultant',\n",
       " \"''\",\n",
       " 'with',\n",
       " 'TIBCO',\n",
       " 'Software',\n",
       " 'Inc.',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'Integration',\n",
       " 'along',\n",
       " 'with',\n",
       " 'TIBCO',\n",
       " 'ActiveMatrix',\n",
       " 'BusinessWorks',\n",
       " ',',\n",
       " 'TIBCO',\n",
       " 'Spotfire',\n",
       " 'proved',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'great',\n",
       " 'experience',\n",
       " 'to',\n",
       " 'me',\n",
       " 'as',\n",
       " 'I',\n",
       " 'had',\n",
       " 'the',\n",
       " 'privilege',\n",
       " 'to',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'most',\n",
       " 'complex',\n",
       " 'business',\n",
       " 'application',\n",
       " ',',\n",
       " 'i.e',\n",
       " '.',\n",
       " 'Middleware.I',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'reusable',\n",
       " 'component',\n",
       " 'that',\n",
       " 'enables',\n",
       " 'the',\n",
       " 'associates',\n",
       " 'in',\n",
       " 'the',\n",
       " 'organization',\n",
       " ';',\n",
       " 'to',\n",
       " 'go',\n",
       " 'through',\n",
       " 'at',\n",
       " 'self-paced',\n",
       " 'training',\n",
       " 'and',\n",
       " 'learning',\n",
       " 'on',\n",
       " 'end',\n",
       " 'to',\n",
       " 'end',\n",
       " 'integration',\n",
       " 'for',\n",
       " 'performing',\n",
       " 'data',\n",
       " 'validation',\n",
       " 'using',\n",
       " 'numerous',\n",
       " 'SOA',\n",
       " 'products',\n",
       " 'like',\n",
       " 'TIBCO',\n",
       " 'ActiveMatrix',\n",
       " 'Business',\n",
       " 'Works',\n",
       " '6',\n",
       " 'integrating',\n",
       " 'and',\n",
       " 'orchestrating',\n",
       " 'the',\n",
       " 'applications',\n",
       " 'flows',\n",
       " ',',\n",
       " 'Clarity',\n",
       " 'for',\n",
       " 'data',\n",
       " 'cleansing',\n",
       " ',',\n",
       " 'M.D.M',\n",
       " '.',\n",
       " 'for',\n",
       " 'the',\n",
       " 'data',\n",
       " 'versioning',\n",
       " ',',\n",
       " 'data',\n",
       " 'storage',\n",
       " 'and',\n",
       " 'TIBCO',\n",
       " 'Spotfire',\n",
       " 'applies',\n",
       " 'to',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " '.',\n",
       " 'I',\n",
       " 'was',\n",
       " 'exposed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'of',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'and',\n",
       " 'logicaally',\n",
       " 'analyzing',\n",
       " 'them',\n",
       " 'and',\n",
       " 'implement',\n",
       " 'the',\n",
       " 'complex',\n",
       " 'business',\n",
       " 'scenarios.I',\n",
       " 'found',\n",
       " 'that',\n",
       " 'Ireland',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fastest',\n",
       " 'growing',\n",
       " 'tech',\n",
       " 'sector',\n",
       " 'and',\n",
       " 'known',\n",
       " 'as',\n",
       " 'the',\n",
       " '``',\n",
       " 'Silicon',\n",
       " 'Valley',\n",
       " 'of',\n",
       " 'Europe',\n",
       " '”',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'been',\n",
       " 'ranked',\n",
       " 'No',\n",
       " '.',\n",
       " '1',\n",
       " 'for',\n",
       " 'Research',\n",
       " 'by',\n",
       " 'Times',\n",
       " 'Higher',\n",
       " 'Education',\n",
       " \"'16\",\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'Europe',\n",
       " \"'s\",\n",
       " 'leading',\n",
       " 'research-intensive',\n",
       " 'universities',\n",
       " ';',\n",
       " 'an',\n",
       " 'environment',\n",
       " 'where',\n",
       " 'undergrads',\n",
       " 'edu',\n",
       " ',',\n",
       " 'masters',\n",
       " 'and',\n",
       " 'PhD',\n",
       " 'training',\n",
       " ',',\n",
       " 'research',\n",
       " ',',\n",
       " 'innovation',\n",
       " 'and',\n",
       " 'community',\n",
       " 'enrisent',\n",
       " 'form',\n",
       " 'a',\n",
       " 'dynamic',\n",
       " 'spectrum',\n",
       " 'of',\n",
       " 'activity',\n",
       " '.',\n",
       " 'The',\n",
       " 'strek',\n",
       " 'of',\n",
       " 'research',\n",
       " 'and',\n",
       " 'innovation',\n",
       " 'at',\n",
       " 'U.C.D.',\n",
       " ',',\n",
       " 'Ireland',\n",
       " 'embraces',\n",
       " 'scholars',\n",
       " ',',\n",
       " 'research',\n",
       " 'groups',\n",
       " 'and',\n",
       " 'collaborations',\n",
       " 'with',\n",
       " 'industry',\n",
       " 'and',\n",
       " 'other',\n",
       " 'technology',\n",
       " 'partners',\n",
       " '.',\n",
       " 'Her',\n",
       " 'eagerness',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'machinery',\n",
       " 'saw',\n",
       " 'her',\n",
       " 'undertake',\n",
       " 'various',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'courses',\n",
       " 'and',\n",
       " 'certifications',\n",
       " 'like',\n",
       " 'Linux',\n",
       " 'Boot',\n",
       " 'camp',\n",
       " ',',\n",
       " 'Python',\n",
       " ',',\n",
       " 'Core',\n",
       " 'Java',\n",
       " ',',\n",
       " '.Net',\n",
       " ':',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " '(',\n",
       " 'C',\n",
       " '#',\n",
       " ')',\n",
       " 'by',\n",
       " 'Microsoft',\n",
       " 'Academy',\n",
       " '.',\n",
       " 'She',\n",
       " 'even',\n",
       " 'presented',\n",
       " 'a',\n",
       " 'seminar',\n",
       " 'fasting',\n",
       " 'on',\n",
       " '‘',\n",
       " 'Prevention',\n",
       " 'of',\n",
       " 'Rogue',\n",
       " 'Access',\n",
       " 'Point',\n",
       " 'using',\n",
       " 'Device',\n",
       " 'Fingerprinting',\n",
       " 'in',\n",
       " 'Wireless',\n",
       " 'Network',\n",
       " '’',\n",
       " '.',\n",
       " 'Thanks',\n",
       " 'for',\n",
       " 'your',\n",
       " 'support',\n",
       " 'bdw',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "token_words = word_tokenize(inputFile)\n",
    "token_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP2.  NORMALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'ms.',\n",
       " 'simmy',\n",
       " ',',\n",
       " 'following',\n",
       " 'is',\n",
       " 'a',\n",
       " 'narrative',\n",
       " 'story',\n",
       " 'of',\n",
       " 'a',\n",
       " 'girly',\n",
       " 'girl',\n",
       " 'named',\n",
       " 'as',\n",
       " 'katy',\n",
       " '.',\n",
       " 'working',\n",
       " 'as',\n",
       " 'a',\n",
       " '``',\n",
       " 'jr',\n",
       " '.',\n",
       " 'consultant',\n",
       " \"''\",\n",
       " 'with',\n",
       " 'tibco',\n",
       " 'software',\n",
       " 'inc.',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'integration',\n",
       " 'along',\n",
       " 'with',\n",
       " 'tibco',\n",
       " 'activematrix',\n",
       " 'businessworks',\n",
       " ',',\n",
       " 'tibco',\n",
       " 'spotfire',\n",
       " 'proved',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'great',\n",
       " 'experience',\n",
       " 'to',\n",
       " 'me',\n",
       " 'as',\n",
       " 'i',\n",
       " 'had',\n",
       " 'the',\n",
       " 'privilege',\n",
       " 'to',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'most',\n",
       " 'complex',\n",
       " 'business',\n",
       " 'application',\n",
       " ',',\n",
       " 'i.e',\n",
       " '.',\n",
       " 'middleware.i',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'reusable',\n",
       " 'component',\n",
       " 'that',\n",
       " 'enables',\n",
       " 'the',\n",
       " 'associates',\n",
       " 'in',\n",
       " 'the',\n",
       " 'organization',\n",
       " ';',\n",
       " 'to',\n",
       " 'go',\n",
       " 'through',\n",
       " 'at',\n",
       " 'self-paced',\n",
       " 'training',\n",
       " 'and',\n",
       " 'learning',\n",
       " 'on',\n",
       " 'end',\n",
       " 'to',\n",
       " 'end',\n",
       " 'integration',\n",
       " 'for',\n",
       " 'performing',\n",
       " 'data',\n",
       " 'validation',\n",
       " 'using',\n",
       " 'numerous',\n",
       " 'soa',\n",
       " 'products',\n",
       " 'like',\n",
       " 'tibco',\n",
       " 'activematrix',\n",
       " 'business',\n",
       " 'works',\n",
       " '6',\n",
       " 'integrating',\n",
       " 'and',\n",
       " 'orchestrating',\n",
       " 'the',\n",
       " 'applications',\n",
       " 'flows',\n",
       " ',',\n",
       " 'clarity',\n",
       " 'for',\n",
       " 'data',\n",
       " 'cleansing',\n",
       " ',',\n",
       " 'm.d.m',\n",
       " '.',\n",
       " 'for',\n",
       " 'the',\n",
       " 'data',\n",
       " 'versioning',\n",
       " ',',\n",
       " 'data',\n",
       " 'storage',\n",
       " 'and',\n",
       " 'tibco',\n",
       " 'spotfire',\n",
       " 'applies',\n",
       " 'to',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'i',\n",
       " 'was',\n",
       " 'exposed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'of',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'and',\n",
       " 'logicaally',\n",
       " 'analyzing',\n",
       " 'them',\n",
       " 'and',\n",
       " 'implement',\n",
       " 'the',\n",
       " 'complex',\n",
       " 'business',\n",
       " 'scenarios.i',\n",
       " 'found',\n",
       " 'that',\n",
       " 'ireland',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fastest',\n",
       " 'growing',\n",
       " 'tech',\n",
       " 'sector',\n",
       " 'and',\n",
       " 'known',\n",
       " 'as',\n",
       " 'the',\n",
       " '``',\n",
       " 'silicon',\n",
       " 'valley',\n",
       " 'of',\n",
       " 'europe',\n",
       " '”',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'been',\n",
       " 'ranked',\n",
       " 'no',\n",
       " '.',\n",
       " '1',\n",
       " 'for',\n",
       " 'research',\n",
       " 'by',\n",
       " 'times',\n",
       " 'higher',\n",
       " 'education',\n",
       " \"'16\",\n",
       " '.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'europe',\n",
       " \"'s\",\n",
       " 'leading',\n",
       " 'research-intensive',\n",
       " 'universities',\n",
       " ';',\n",
       " 'an',\n",
       " 'environment',\n",
       " 'where',\n",
       " 'undergrads',\n",
       " 'edu',\n",
       " ',',\n",
       " 'masters',\n",
       " 'and',\n",
       " 'phd',\n",
       " 'training',\n",
       " ',',\n",
       " 'research',\n",
       " ',',\n",
       " 'innovation',\n",
       " 'and',\n",
       " 'community',\n",
       " 'enrisent',\n",
       " 'form',\n",
       " 'a',\n",
       " 'dynamic',\n",
       " 'spectrum',\n",
       " 'of',\n",
       " 'activity',\n",
       " '.',\n",
       " 'the',\n",
       " 'strek',\n",
       " 'of',\n",
       " 'research',\n",
       " 'and',\n",
       " 'innovation',\n",
       " 'at',\n",
       " 'u.c.d.',\n",
       " ',',\n",
       " 'ireland',\n",
       " 'embraces',\n",
       " 'scholars',\n",
       " ',',\n",
       " 'research',\n",
       " 'groups',\n",
       " 'and',\n",
       " 'collaborations',\n",
       " 'with',\n",
       " 'industry',\n",
       " 'and',\n",
       " 'other',\n",
       " 'technology',\n",
       " 'partners',\n",
       " '.',\n",
       " 'her',\n",
       " 'eagerness',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'machinery',\n",
       " 'saw',\n",
       " 'her',\n",
       " 'undertake',\n",
       " 'various',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'courses',\n",
       " 'and',\n",
       " 'certifications',\n",
       " 'like',\n",
       " 'linux',\n",
       " 'boot',\n",
       " 'camp',\n",
       " ',',\n",
       " 'python',\n",
       " ',',\n",
       " 'core',\n",
       " 'java',\n",
       " ',',\n",
       " '.net',\n",
       " ':',\n",
       " 'c',\n",
       " 'sharp',\n",
       " '(',\n",
       " 'c',\n",
       " '#',\n",
       " ')',\n",
       " 'by',\n",
       " 'microsoft',\n",
       " 'academy',\n",
       " '.',\n",
       " 'she',\n",
       " 'even',\n",
       " 'presented',\n",
       " 'a',\n",
       " 'seminar',\n",
       " 'fasting',\n",
       " 'on',\n",
       " '‘',\n",
       " 'prevention',\n",
       " 'of',\n",
       " 'rogue',\n",
       " 'access',\n",
       " 'point',\n",
       " 'using',\n",
       " 'device',\n",
       " 'fingerprinting',\n",
       " 'in',\n",
       " 'wireless',\n",
       " 'network',\n",
       " '’',\n",
       " '.',\n",
       " 'thanks',\n",
       " 'for',\n",
       " 'your',\n",
       " 'support',\n",
       " 'bdw',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lowercase\n",
    "\n",
    "normal_word = []\n",
    "normal_word = [i.lower() for i in token_words]\n",
    "normal_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'ms.',\n",
       " 'simmy',\n",
       " ',',\n",
       " 'following',\n",
       " 'narrative',\n",
       " 'story',\n",
       " 'girly',\n",
       " 'girl',\n",
       " 'named',\n",
       " 'katy',\n",
       " '.',\n",
       " 'working',\n",
       " '``',\n",
       " 'jr',\n",
       " '.',\n",
       " 'consultant',\n",
       " \"''\",\n",
       " 'tibco',\n",
       " 'software',\n",
       " 'inc.',\n",
       " ',',\n",
       " 'field',\n",
       " 'integration',\n",
       " 'along',\n",
       " 'tibco',\n",
       " 'activematrix',\n",
       " 'businessworks',\n",
       " ',',\n",
       " 'tibco',\n",
       " 'spotfire',\n",
       " 'proved',\n",
       " 'great',\n",
       " 'experience',\n",
       " 'privilege',\n",
       " 'deal',\n",
       " 'complex',\n",
       " 'business',\n",
       " 'application',\n",
       " ',',\n",
       " 'i.e',\n",
       " '.',\n",
       " 'middleware.i',\n",
       " 'developed',\n",
       " 'reusable',\n",
       " 'component',\n",
       " 'enables',\n",
       " 'associates',\n",
       " 'organization',\n",
       " ';',\n",
       " 'go',\n",
       " 'self-paced',\n",
       " 'training',\n",
       " 'learning',\n",
       " 'end',\n",
       " 'end',\n",
       " 'integration',\n",
       " 'performing',\n",
       " 'data',\n",
       " 'validation',\n",
       " 'using',\n",
       " 'numerous',\n",
       " 'soa',\n",
       " 'products',\n",
       " 'like',\n",
       " 'tibco',\n",
       " 'activematrix',\n",
       " 'business',\n",
       " 'works',\n",
       " '6',\n",
       " 'integrating',\n",
       " 'orchestrating',\n",
       " 'applications',\n",
       " 'flows',\n",
       " ',',\n",
       " 'clarity',\n",
       " 'data',\n",
       " 'cleansing',\n",
       " ',',\n",
       " 'm.d.m',\n",
       " '.',\n",
       " 'data',\n",
       " 'versioning',\n",
       " ',',\n",
       " 'data',\n",
       " 'storage',\n",
       " 'tibco',\n",
       " 'spotfire',\n",
       " 'applies',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'exposed',\n",
       " 'opportunity',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'logicaally',\n",
       " 'analyzing',\n",
       " 'implement',\n",
       " 'complex',\n",
       " 'business',\n",
       " 'scenarios.i',\n",
       " 'found',\n",
       " 'ireland',\n",
       " 'one',\n",
       " 'fastest',\n",
       " 'growing',\n",
       " 'tech',\n",
       " 'sector',\n",
       " 'known',\n",
       " '``',\n",
       " 'silicon',\n",
       " 'valley',\n",
       " 'europe',\n",
       " '”',\n",
       " '.',\n",
       " 'ranked',\n",
       " '.',\n",
       " '1',\n",
       " 'research',\n",
       " 'times',\n",
       " 'higher',\n",
       " 'education',\n",
       " \"'16\",\n",
       " '.',\n",
       " 'one',\n",
       " 'europe',\n",
       " \"'s\",\n",
       " 'leading',\n",
       " 'research-intensive',\n",
       " 'universities',\n",
       " ';',\n",
       " 'environment',\n",
       " 'undergrads',\n",
       " 'edu',\n",
       " ',',\n",
       " 'masters',\n",
       " 'phd',\n",
       " 'training',\n",
       " ',',\n",
       " 'research',\n",
       " ',',\n",
       " 'innovation',\n",
       " 'community',\n",
       " 'enrisent',\n",
       " 'form',\n",
       " 'dynamic',\n",
       " 'spectrum',\n",
       " 'activity',\n",
       " '.',\n",
       " 'strek',\n",
       " 'research',\n",
       " 'innovation',\n",
       " 'u.c.d.',\n",
       " ',',\n",
       " 'ireland',\n",
       " 'embraces',\n",
       " 'scholars',\n",
       " ',',\n",
       " 'research',\n",
       " 'groups',\n",
       " 'collaborations',\n",
       " 'industry',\n",
       " 'technology',\n",
       " 'partners',\n",
       " '.',\n",
       " 'eagerness',\n",
       " 'learn',\n",
       " 'machinery',\n",
       " 'saw',\n",
       " 'undertake',\n",
       " 'various',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'courses',\n",
       " 'certifications',\n",
       " 'like',\n",
       " 'linux',\n",
       " 'boot',\n",
       " 'camp',\n",
       " ',',\n",
       " 'python',\n",
       " ',',\n",
       " 'core',\n",
       " 'java',\n",
       " ',',\n",
       " '.net',\n",
       " ':',\n",
       " 'c',\n",
       " 'sharp',\n",
       " '(',\n",
       " 'c',\n",
       " '#',\n",
       " ')',\n",
       " 'microsoft',\n",
       " 'academy',\n",
       " '.',\n",
       " 'even',\n",
       " 'presented',\n",
       " 'seminar',\n",
       " 'fasting',\n",
       " '‘',\n",
       " 'prevention',\n",
       " 'rogue',\n",
       " 'access',\n",
       " 'point',\n",
       " 'using',\n",
       " 'device',\n",
       " 'fingerprinting',\n",
       " 'wireless',\n",
       " 'network',\n",
       " '’',\n",
       " '.',\n",
       " 'thanks',\n",
       " 'support',\n",
       " 'bdw',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stopword Removal\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "swords = stopwords.words('english')\n",
    "filtered_words = []\n",
    "filtered_words = [w for w in normal_word if w not in swords]\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: POS-TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 'NN'),\n",
       " ('ms.', 'NN'),\n",
       " ('simmy', 'NN'),\n",
       " (',', ','),\n",
       " ('following', 'VBG'),\n",
       " ('narrative', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('girly', 'RB'),\n",
       " ('girl', 'NN'),\n",
       " ('named', 'VBN'),\n",
       " ('katy', 'NN'),\n",
       " ('.', '.'),\n",
       " ('working', 'VBG'),\n",
       " ('``', '``'),\n",
       " ('jr', 'NN'),\n",
       " ('.', '.'),\n",
       " ('consultant', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('tibco', 'NN'),\n",
       " ('software', 'NN'),\n",
       " ('inc.', 'NN'),\n",
       " (',', ','),\n",
       " ('field', 'NN'),\n",
       " ('integration', 'NN'),\n",
       " ('along', 'IN'),\n",
       " ('tibco', 'NN'),\n",
       " ('activematrix', 'NN'),\n",
       " ('businessworks', 'NNS'),\n",
       " (',', ','),\n",
       " ('tibco', 'NN'),\n",
       " ('spotfire', 'NN'),\n",
       " ('proved', 'VBD'),\n",
       " ('great', 'JJ'),\n",
       " ('experience', 'NN'),\n",
       " ('privilege', 'NN'),\n",
       " ('deal', 'NN'),\n",
       " ('complex', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " ('application', 'NN'),\n",
       " (',', ','),\n",
       " ('i.e', 'NN'),\n",
       " ('.', '.'),\n",
       " ('middleware.i', 'NN'),\n",
       " ('developed', 'VBD'),\n",
       " ('reusable', 'JJ'),\n",
       " ('component', 'NN'),\n",
       " ('enables', 'NNS'),\n",
       " ('associates', 'VBZ'),\n",
       " ('organization', 'NN'),\n",
       " (';', ':'),\n",
       " ('go', 'VB'),\n",
       " ('self-paced', 'JJ'),\n",
       " ('training', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('end', 'JJ'),\n",
       " ('end', 'NN'),\n",
       " ('integration', 'NN'),\n",
       " ('performing', 'VBG'),\n",
       " ('data', 'NNS'),\n",
       " ('validation', 'NN'),\n",
       " ('using', 'VBG'),\n",
       " ('numerous', 'JJ'),\n",
       " ('soa', 'JJ'),\n",
       " ('products', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('tibco', 'NN'),\n",
       " ('activematrix', 'NN'),\n",
       " ('business', 'NN'),\n",
       " ('works', 'VBZ'),\n",
       " ('6', 'CD'),\n",
       " ('integrating', 'VBG'),\n",
       " ('orchestrating', 'VBG'),\n",
       " ('applications', 'NNS'),\n",
       " ('flows', 'NNS'),\n",
       " (',', ','),\n",
       " ('clarity', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('cleansing', 'NN'),\n",
       " (',', ','),\n",
       " ('m.d.m', 'NN'),\n",
       " ('.', '.'),\n",
       " ('data', 'NNS'),\n",
       " ('versioning', 'NN'),\n",
       " (',', ','),\n",
       " ('data', 'NNS'),\n",
       " ('storage', 'NN'),\n",
       " ('tibco', 'NN'),\n",
       " ('spotfire', 'NN'),\n",
       " ('applies', 'NNS'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('.', '.'),\n",
       " ('exposed', 'VBN'),\n",
       " ('opportunity', 'NN'),\n",
       " ('problem', 'NN'),\n",
       " ('solving', 'VBG'),\n",
       " ('logicaally', 'RB'),\n",
       " ('analyzing', 'VBG'),\n",
       " ('implement', 'NN'),\n",
       " ('complex', 'NN'),\n",
       " ('business', 'NN'),\n",
       " ('scenarios.i', 'NN'),\n",
       " ('found', 'VBD'),\n",
       " ('ireland', 'RB'),\n",
       " ('one', 'CD'),\n",
       " ('fastest', 'JJS'),\n",
       " ('growing', 'VBG'),\n",
       " ('tech', 'JJ'),\n",
       " ('sector', 'NN'),\n",
       " ('known', 'VBN'),\n",
       " ('``', '``'),\n",
       " ('silicon', 'JJ'),\n",
       " ('valley', 'NN'),\n",
       " ('europe', 'NN'),\n",
       " ('”', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('ranked', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('1', 'CD'),\n",
       " ('research', 'NN'),\n",
       " ('times', 'NNS'),\n",
       " ('higher', 'JJR'),\n",
       " ('education', 'NN'),\n",
       " (\"'16\", 'POS'),\n",
       " ('.', '.'),\n",
       " ('one', 'CD'),\n",
       " ('europe', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('leading', 'JJ'),\n",
       " ('research-intensive', 'JJ'),\n",
       " ('universities', 'NNS'),\n",
       " (';', ':'),\n",
       " ('environment', 'NN'),\n",
       " ('undergrads', 'NNS'),\n",
       " ('edu', 'RB'),\n",
       " (',', ','),\n",
       " ('masters', 'NNS'),\n",
       " ('phd', 'VBP'),\n",
       " ('training', 'NN'),\n",
       " (',', ','),\n",
       " ('research', 'NN'),\n",
       " (',', ','),\n",
       " ('innovation', 'NN'),\n",
       " ('community', 'NN'),\n",
       " ('enrisent', 'JJ'),\n",
       " ('form', 'NN'),\n",
       " ('dynamic', 'JJ'),\n",
       " ('spectrum', 'JJ'),\n",
       " ('activity', 'NN'),\n",
       " ('.', '.'),\n",
       " ('strek', 'JJ'),\n",
       " ('research', 'NN'),\n",
       " ('innovation', 'NN'),\n",
       " ('u.c.d.', 'NN'),\n",
       " (',', ','),\n",
       " ('ireland', 'NN'),\n",
       " ('embraces', 'NNS'),\n",
       " ('scholars', 'NNS'),\n",
       " (',', ','),\n",
       " ('research', 'NN'),\n",
       " ('groups', 'NNS'),\n",
       " ('collaborations', 'NNS'),\n",
       " ('industry', 'NN'),\n",
       " ('technology', 'NN'),\n",
       " ('partners', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('eagerness', 'NN'),\n",
       " ('learn', 'JJ'),\n",
       " ('machinery', 'NN'),\n",
       " ('saw', 'VBD'),\n",
       " ('undertake', 'JJ'),\n",
       " ('various', 'JJ'),\n",
       " ('programming', 'VBG'),\n",
       " ('language', 'NN'),\n",
       " ('courses', 'NNS'),\n",
       " ('certifications', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('linux', 'JJ'),\n",
       " ('boot', 'NN'),\n",
       " ('camp', 'NN'),\n",
       " (',', ','),\n",
       " ('python', 'NN'),\n",
       " (',', ','),\n",
       " ('core', 'NN'),\n",
       " ('java', 'NN'),\n",
       " (',', ','),\n",
       " ('.net', 'NN'),\n",
       " (':', ':'),\n",
       " ('c', 'NN'),\n",
       " ('sharp', 'JJ'),\n",
       " ('(', '('),\n",
       " ('c', 'JJ'),\n",
       " ('#', '#'),\n",
       " (')', ')'),\n",
       " ('microsoft', 'FW'),\n",
       " ('academy', 'NN'),\n",
       " ('.', '.'),\n",
       " ('even', 'RB'),\n",
       " ('presented', 'VBD'),\n",
       " ('seminar', 'JJ'),\n",
       " ('fasting', 'VBG'),\n",
       " ('‘', 'JJ'),\n",
       " ('prevention', 'NN'),\n",
       " ('rogue', 'NN'),\n",
       " ('access', 'NN'),\n",
       " ('point', 'NN'),\n",
       " ('using', 'VBG'),\n",
       " ('device', 'NN'),\n",
       " ('fingerprinting', 'VBG'),\n",
       " ('wireless', 'NN'),\n",
       " ('network', 'NN'),\n",
       " ('’', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('thanks', 'NNS'),\n",
       " ('support', 'NN'),\n",
       " ('bdw', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "posWords = pos_tag(filtered_words)\n",
    "posWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: \n",
    "Now, take a second, new text-file do the following:\n",
    "\n",
    "    a. Tokenize a new text-file (200 words) and the stem it using Porter Stemming. Report your answer and some of weird    things that Porter Stemming does.\n",
    "    \n",
    "    b. Tokenize the new text-file and then lemmatize it using WordNet Lemmatizer; note you may have to pos-tag the sentences first and then convert the tags to make this work. Report the result of these steps and point out some of the things that look wrong.\n",
    "    \n",
    "    c. Compare the outputs from Porter Stemming and the Lemmatisation of the same file. Which do you think is the best to use and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Mr. Timmy Following is a story of a girly girl named as KATY\\'18. Working as a \"Jr. Consultant\" with TIBCO Software Inc., in the field of Integration along with T.I.B.C.O. BusinessWorks proved to be great experience to me as I had the privilege to work most complex part of any application, i.e Middleware. Snow comprises individual ice crystals that grow while suspended in the atmosphere—usually within clouds—and then fall, accumulating on the ground where they undergo further changes. As a child, I loved sitting on my grandfather\\'s lap while he read me stories.As a child, I was blissfully unaware that, as I listened to the stories, I was also learning new words and ways in which those new words combined to communicate ideas, life lessons.A good Europe\\'s story encourages us to turn the next page and read more. We want to find out what happens next and what the main characters do and what they say to each other. We may feel excited, sad, afraid, angry or really happy. Do you think that with Impact Wrestling moving to AXS, a lot more eyes will be on the product? This week, as good as the show was, there were only 3,500 people watching on the Twitch stream, and that was the upper limit number during the stream. This is why the words that relate a story\\'s events,conversations are processed in this deeper way.In fact, cultures all around the world have always used storytelling to pass knowledge from one generation to another.The tech. merges two concepts from two different fields.Last but not the least here’s an example of Stemming- It is very essential to pythonly while you are pythoning with the Python language. All Pythonistas must have pythoned badly at least once.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "\n",
    "fh = open(r\"Input_2.txt\",\"r\", encoding=\"utf8\")\n",
    "Q2_input=fh.read()\n",
    "Q2_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "token_word_Q2 = word_tokenize(Q2_input)\n",
    "for i in token_word_Q2:\n",
    "    count+=1\n",
    "    \n",
    "count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Mr.',\n",
       " 'Timmy',\n",
       " 'Following',\n",
       " 'is',\n",
       " 'a',\n",
       " 'story',\n",
       " 'of',\n",
       " 'a',\n",
       " 'girly',\n",
       " 'girl',\n",
       " 'named',\n",
       " 'as',\n",
       " \"KATY'18\",\n",
       " '.',\n",
       " 'Working',\n",
       " 'as',\n",
       " 'a',\n",
       " '``',\n",
       " 'Jr',\n",
       " '.',\n",
       " 'Consultant',\n",
       " \"''\",\n",
       " 'with',\n",
       " 'TIBCO',\n",
       " 'Software',\n",
       " 'Inc.',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'Integration',\n",
       " 'along',\n",
       " 'with',\n",
       " 'T.I.B.C.O',\n",
       " '.',\n",
       " 'BusinessWorks',\n",
       " 'proved',\n",
       " 'to',\n",
       " 'be',\n",
       " 'great',\n",
       " 'experience',\n",
       " 'to',\n",
       " 'me',\n",
       " 'as',\n",
       " 'I',\n",
       " 'had',\n",
       " 'the',\n",
       " 'privilege',\n",
       " 'to',\n",
       " 'work',\n",
       " 'most',\n",
       " 'complex',\n",
       " 'part',\n",
       " 'of',\n",
       " 'any',\n",
       " 'application',\n",
       " ',',\n",
       " 'i.e',\n",
       " 'Middleware',\n",
       " '.',\n",
       " 'Snow',\n",
       " 'comprises',\n",
       " 'individual',\n",
       " 'ice',\n",
       " 'crystals',\n",
       " 'that',\n",
       " 'grow',\n",
       " 'while',\n",
       " 'suspended',\n",
       " 'in',\n",
       " 'the',\n",
       " 'atmosphere—usually',\n",
       " 'within',\n",
       " 'clouds—and',\n",
       " 'then',\n",
       " 'fall',\n",
       " ',',\n",
       " 'accumulating',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ground',\n",
       " 'where',\n",
       " 'they',\n",
       " 'undergo',\n",
       " 'further',\n",
       " 'changes',\n",
       " '.',\n",
       " 'As',\n",
       " 'a',\n",
       " 'child',\n",
       " ',',\n",
       " 'I',\n",
       " 'loved',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'my',\n",
       " 'grandfather',\n",
       " \"'s\",\n",
       " 'lap',\n",
       " 'while',\n",
       " 'he',\n",
       " 'read',\n",
       " 'me',\n",
       " 'stories.As',\n",
       " 'a',\n",
       " 'child',\n",
       " ',',\n",
       " 'I',\n",
       " 'was',\n",
       " 'blissfully',\n",
       " 'unaware',\n",
       " 'that',\n",
       " ',',\n",
       " 'as',\n",
       " 'I',\n",
       " 'listened',\n",
       " 'to',\n",
       " 'the',\n",
       " 'stories',\n",
       " ',',\n",
       " 'I',\n",
       " 'was',\n",
       " 'also',\n",
       " 'learning',\n",
       " 'new',\n",
       " 'words',\n",
       " 'and',\n",
       " 'ways',\n",
       " 'in',\n",
       " 'which',\n",
       " 'those',\n",
       " 'new',\n",
       " 'words',\n",
       " 'combined',\n",
       " 'to',\n",
       " 'communicate',\n",
       " 'ideas',\n",
       " ',',\n",
       " 'life',\n",
       " 'lessons.A',\n",
       " 'good',\n",
       " 'Europe',\n",
       " \"'s\",\n",
       " 'story',\n",
       " 'encourages',\n",
       " 'us',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'next',\n",
       " 'page',\n",
       " 'and',\n",
       " 'read',\n",
       " 'more',\n",
       " '.',\n",
       " 'We',\n",
       " 'want',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'what',\n",
       " 'happens',\n",
       " 'next',\n",
       " 'and',\n",
       " 'what',\n",
       " 'the',\n",
       " 'main',\n",
       " 'characters',\n",
       " 'do',\n",
       " 'and',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'to',\n",
       " 'each',\n",
       " 'other',\n",
       " '.',\n",
       " 'We',\n",
       " 'may',\n",
       " 'feel',\n",
       " 'excited',\n",
       " ',',\n",
       " 'sad',\n",
       " ',',\n",
       " 'afraid',\n",
       " ',',\n",
       " 'angry',\n",
       " 'or',\n",
       " 'really',\n",
       " 'happy',\n",
       " '.',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'that',\n",
       " 'with',\n",
       " 'Impact',\n",
       " 'Wrestling',\n",
       " 'moving',\n",
       " 'to',\n",
       " 'AXS',\n",
       " ',',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'more',\n",
       " 'eyes',\n",
       " 'will',\n",
       " 'be',\n",
       " 'on',\n",
       " 'the',\n",
       " 'product',\n",
       " '?',\n",
       " 'This',\n",
       " 'week',\n",
       " ',',\n",
       " 'as',\n",
       " 'good',\n",
       " 'as',\n",
       " 'the',\n",
       " 'show',\n",
       " 'was',\n",
       " ',',\n",
       " 'there',\n",
       " 'were',\n",
       " 'only',\n",
       " '3,500',\n",
       " 'people',\n",
       " 'watching',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Twitch',\n",
       " 'stream',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " 'was',\n",
       " 'the',\n",
       " 'upper',\n",
       " 'limit',\n",
       " 'number',\n",
       " 'during',\n",
       " 'the',\n",
       " 'stream',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'why',\n",
       " 'the',\n",
       " 'words',\n",
       " 'that',\n",
       " 'relate',\n",
       " 'a',\n",
       " 'story',\n",
       " \"'s\",\n",
       " 'events',\n",
       " ',',\n",
       " 'conversations',\n",
       " 'are',\n",
       " 'processed',\n",
       " 'in',\n",
       " 'this',\n",
       " 'deeper',\n",
       " 'way.In',\n",
       " 'fact',\n",
       " ',',\n",
       " 'cultures',\n",
       " 'all',\n",
       " 'around',\n",
       " 'the',\n",
       " 'world',\n",
       " 'have',\n",
       " 'always',\n",
       " 'used',\n",
       " 'storytelling',\n",
       " 'to',\n",
       " 'pass',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'one',\n",
       " 'generation',\n",
       " 'to',\n",
       " 'another.The',\n",
       " 'tech',\n",
       " '.',\n",
       " 'merges',\n",
       " 'two',\n",
       " 'concepts',\n",
       " 'from',\n",
       " 'two',\n",
       " 'different',\n",
       " 'fields.Last',\n",
       " 'but',\n",
       " 'not',\n",
       " 'the',\n",
       " 'least',\n",
       " 'here',\n",
       " '’',\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'Stemming-',\n",
       " 'It',\n",
       " 'is',\n",
       " 'very',\n",
       " 'essential',\n",
       " 'to',\n",
       " 'pythonly',\n",
       " 'while',\n",
       " 'you',\n",
       " 'are',\n",
       " 'pythoning',\n",
       " 'with',\n",
       " 'the',\n",
       " 'Python',\n",
       " 'language',\n",
       " '.',\n",
       " 'All',\n",
       " 'Pythonistas',\n",
       " 'must',\n",
       " 'have',\n",
       " 'pythoned',\n",
       " 'badly',\n",
       " 'at',\n",
       " 'least',\n",
       " 'once',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_word_Q2 = word_tokenize(Q2_input)\n",
    "token_word_Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "mr.\n",
      "timmi\n",
      "follow\n",
      "is\n",
      "a\n",
      "stori\n",
      "of\n",
      "a\n",
      "girli\n",
      "girl\n",
      "name\n",
      "as\n",
      "katy'18\n",
      ".\n",
      "work\n",
      "as\n",
      "a\n",
      "``\n",
      "Jr\n",
      ".\n",
      "consult\n",
      "''\n",
      "with\n",
      "tibco\n",
      "softwar\n",
      "inc.\n",
      ",\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "integr\n",
      "along\n",
      "with\n",
      "t.i.b.c.o\n",
      ".\n",
      "businesswork\n",
      "prove\n",
      "to\n",
      "be\n",
      "great\n",
      "experi\n",
      "to\n",
      "me\n",
      "as\n",
      "I\n",
      "had\n",
      "the\n",
      "privileg\n",
      "to\n",
      "work\n",
      "most\n",
      "complex\n",
      "part\n",
      "of\n",
      "ani\n",
      "applic\n",
      ",\n",
      "i.e\n",
      "middlewar\n",
      ".\n",
      "snow\n",
      "compris\n",
      "individu\n",
      "ice\n",
      "crystal\n",
      "that\n",
      "grow\n",
      "while\n",
      "suspend\n",
      "in\n",
      "the\n",
      "atmosphere—usu\n",
      "within\n",
      "clouds—and\n",
      "then\n",
      "fall\n",
      ",\n",
      "accumul\n",
      "on\n",
      "the\n",
      "ground\n",
      "where\n",
      "they\n",
      "undergo\n",
      "further\n",
      "chang\n",
      ".\n",
      "As\n",
      "a\n",
      "child\n",
      ",\n",
      "I\n",
      "love\n",
      "sit\n",
      "on\n",
      "my\n",
      "grandfath\n",
      "'s\n",
      "lap\n",
      "while\n",
      "he\n",
      "read\n",
      "me\n",
      "stories.a\n",
      "a\n",
      "child\n",
      ",\n",
      "I\n",
      "wa\n",
      "bliss\n",
      "unawar\n",
      "that\n",
      ",\n",
      "as\n",
      "I\n",
      "listen\n",
      "to\n",
      "the\n",
      "stori\n",
      ",\n",
      "I\n",
      "wa\n",
      "also\n",
      "learn\n",
      "new\n",
      "word\n",
      "and\n",
      "way\n",
      "in\n",
      "which\n",
      "those\n",
      "new\n",
      "word\n",
      "combin\n",
      "to\n",
      "commun\n",
      "idea\n",
      ",\n",
      "life\n",
      "lessons.a\n",
      "good\n",
      "europ\n",
      "'s\n",
      "stori\n",
      "encourag\n",
      "us\n",
      "to\n",
      "turn\n",
      "the\n",
      "next\n",
      "page\n",
      "and\n",
      "read\n",
      "more\n",
      ".\n",
      "We\n",
      "want\n",
      "to\n",
      "find\n",
      "out\n",
      "what\n",
      "happen\n",
      "next\n",
      "and\n",
      "what\n",
      "the\n",
      "main\n",
      "charact\n",
      "do\n",
      "and\n",
      "what\n",
      "they\n",
      "say\n",
      "to\n",
      "each\n",
      "other\n",
      ".\n",
      "We\n",
      "may\n",
      "feel\n",
      "excit\n",
      ",\n",
      "sad\n",
      ",\n",
      "afraid\n",
      ",\n",
      "angri\n",
      "or\n",
      "realli\n",
      "happi\n",
      ".\n",
      "Do\n",
      "you\n",
      "think\n",
      "that\n",
      "with\n",
      "impact\n",
      "wrestl\n",
      "move\n",
      "to\n",
      "ax\n",
      ",\n",
      "a\n",
      "lot\n",
      "more\n",
      "eye\n",
      "will\n",
      "be\n",
      "on\n",
      "the\n",
      "product\n",
      "?\n",
      "thi\n",
      "week\n",
      ",\n",
      "as\n",
      "good\n",
      "as\n",
      "the\n",
      "show\n",
      "wa\n",
      ",\n",
      "there\n",
      "were\n",
      "onli\n",
      "3,500\n",
      "peopl\n",
      "watch\n",
      "on\n",
      "the\n",
      "twitch\n",
      "stream\n",
      ",\n",
      "and\n",
      "that\n",
      "wa\n",
      "the\n",
      "upper\n",
      "limit\n",
      "number\n",
      "dure\n",
      "the\n",
      "stream\n",
      ".\n",
      "thi\n",
      "is\n",
      "whi\n",
      "the\n",
      "word\n",
      "that\n",
      "relat\n",
      "a\n",
      "stori\n",
      "'s\n",
      "event\n",
      ",\n",
      "convers\n",
      "are\n",
      "process\n",
      "in\n",
      "thi\n",
      "deeper\n",
      "way.in\n",
      "fact\n",
      ",\n",
      "cultur\n",
      "all\n",
      "around\n",
      "the\n",
      "world\n",
      "have\n",
      "alway\n",
      "use\n",
      "storytel\n",
      "to\n",
      "pass\n",
      "knowledg\n",
      "from\n",
      "one\n",
      "gener\n",
      "to\n",
      "another.th\n",
      "tech\n",
      ".\n",
      "merg\n",
      "two\n",
      "concept\n",
      "from\n",
      "two\n",
      "differ\n",
      "fields.last\n",
      "but\n",
      "not\n",
      "the\n",
      "least\n",
      "here\n",
      "’\n",
      "s\n",
      "an\n",
      "exampl\n",
      "of\n",
      "stemming-\n",
      "It\n",
      "is\n",
      "veri\n",
      "essenti\n",
      "to\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "the\n",
      "python\n",
      "languag\n",
      ".\n",
      "all\n",
      "pythonista\n",
      "must\n",
      "have\n",
      "python\n",
      "badli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "for i in token_word_Q2:\n",
    "    print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORDNET LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Mr.',\n",
       " 'Timmy',\n",
       " 'Following',\n",
       " 'is',\n",
       " 'a',\n",
       " 'story',\n",
       " 'of',\n",
       " 'a',\n",
       " 'girly',\n",
       " 'girl',\n",
       " 'named',\n",
       " 'as',\n",
       " \"KATY'18\",\n",
       " '.',\n",
       " 'Working',\n",
       " 'as',\n",
       " 'a',\n",
       " '``',\n",
       " 'Jr',\n",
       " '.',\n",
       " 'Consultant',\n",
       " \"''\",\n",
       " 'with',\n",
       " 'TIBCO',\n",
       " 'Software',\n",
       " 'Inc.',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'Integration',\n",
       " 'along',\n",
       " 'with',\n",
       " 'T.I.B.C.O',\n",
       " '.',\n",
       " 'BusinessWorks',\n",
       " 'proved',\n",
       " 'to',\n",
       " 'be',\n",
       " 'great',\n",
       " 'experience',\n",
       " 'to',\n",
       " 'me',\n",
       " 'as',\n",
       " 'I',\n",
       " 'had',\n",
       " 'the',\n",
       " 'privilege',\n",
       " 'to',\n",
       " 'work',\n",
       " 'most',\n",
       " 'complex',\n",
       " 'part',\n",
       " 'of',\n",
       " 'any',\n",
       " 'application',\n",
       " ',',\n",
       " 'i.e',\n",
       " 'Middleware',\n",
       " '.',\n",
       " 'Snow',\n",
       " 'comprises',\n",
       " 'individual',\n",
       " 'ice',\n",
       " 'crystals',\n",
       " 'that',\n",
       " 'grow',\n",
       " 'while',\n",
       " 'suspended',\n",
       " 'in',\n",
       " 'the',\n",
       " 'atmosphere—usually',\n",
       " 'within',\n",
       " 'clouds—and',\n",
       " 'then',\n",
       " 'fall',\n",
       " ',',\n",
       " 'accumulating',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ground',\n",
       " 'where',\n",
       " 'they',\n",
       " 'undergo',\n",
       " 'further',\n",
       " 'changes',\n",
       " '.',\n",
       " 'As',\n",
       " 'a',\n",
       " 'child',\n",
       " ',',\n",
       " 'I',\n",
       " 'loved',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'my',\n",
       " 'grandfather',\n",
       " \"'s\",\n",
       " 'lap',\n",
       " 'while',\n",
       " 'he',\n",
       " 'read',\n",
       " 'me',\n",
       " 'stories.As',\n",
       " 'a',\n",
       " 'child',\n",
       " ',',\n",
       " 'I',\n",
       " 'was',\n",
       " 'blissfully',\n",
       " 'unaware',\n",
       " 'that',\n",
       " ',',\n",
       " 'as',\n",
       " 'I',\n",
       " 'listened',\n",
       " 'to',\n",
       " 'the',\n",
       " 'stories',\n",
       " ',',\n",
       " 'I',\n",
       " 'was',\n",
       " 'also',\n",
       " 'learning',\n",
       " 'new',\n",
       " 'words',\n",
       " 'and',\n",
       " 'ways',\n",
       " 'in',\n",
       " 'which',\n",
       " 'those',\n",
       " 'new',\n",
       " 'words',\n",
       " 'combined',\n",
       " 'to',\n",
       " 'communicate',\n",
       " 'ideas',\n",
       " ',',\n",
       " 'life',\n",
       " 'lessons.A',\n",
       " 'good',\n",
       " 'Europe',\n",
       " \"'s\",\n",
       " 'story',\n",
       " 'encourages',\n",
       " 'us',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'next',\n",
       " 'page',\n",
       " 'and',\n",
       " 'read',\n",
       " 'more',\n",
       " '.',\n",
       " 'We',\n",
       " 'want',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'what',\n",
       " 'happens',\n",
       " 'next',\n",
       " 'and',\n",
       " 'what',\n",
       " 'the',\n",
       " 'main',\n",
       " 'characters',\n",
       " 'do',\n",
       " 'and',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'to',\n",
       " 'each',\n",
       " 'other',\n",
       " '.',\n",
       " 'We',\n",
       " 'may',\n",
       " 'feel',\n",
       " 'excited',\n",
       " ',',\n",
       " 'sad',\n",
       " ',',\n",
       " 'afraid',\n",
       " ',',\n",
       " 'angry',\n",
       " 'or',\n",
       " 'really',\n",
       " 'happy',\n",
       " '.',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'that',\n",
       " 'with',\n",
       " 'Impact',\n",
       " 'Wrestling',\n",
       " 'moving',\n",
       " 'to',\n",
       " 'AXS',\n",
       " ',',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'more',\n",
       " 'eyes',\n",
       " 'will',\n",
       " 'be',\n",
       " 'on',\n",
       " 'the',\n",
       " 'product',\n",
       " '?',\n",
       " 'This',\n",
       " 'week',\n",
       " ',',\n",
       " 'as',\n",
       " 'good',\n",
       " 'as',\n",
       " 'the',\n",
       " 'show',\n",
       " 'was',\n",
       " ',',\n",
       " 'there',\n",
       " 'were',\n",
       " 'only',\n",
       " '3,500',\n",
       " 'people',\n",
       " 'watching',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Twitch',\n",
       " 'stream',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " 'was',\n",
       " 'the',\n",
       " 'upper',\n",
       " 'limit',\n",
       " 'number',\n",
       " 'during',\n",
       " 'the',\n",
       " 'stream',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'why',\n",
       " 'the',\n",
       " 'words',\n",
       " 'that',\n",
       " 'relate',\n",
       " 'a',\n",
       " 'story',\n",
       " \"'s\",\n",
       " 'events',\n",
       " ',',\n",
       " 'conversations',\n",
       " 'are',\n",
       " 'processed',\n",
       " 'in',\n",
       " 'this',\n",
       " 'deeper',\n",
       " 'way.In',\n",
       " 'fact',\n",
       " ',',\n",
       " 'cultures',\n",
       " 'all',\n",
       " 'around',\n",
       " 'the',\n",
       " 'world',\n",
       " 'have',\n",
       " 'always',\n",
       " 'used',\n",
       " 'storytelling',\n",
       " 'to',\n",
       " 'pass',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'one',\n",
       " 'generation',\n",
       " 'to',\n",
       " 'another.The',\n",
       " 'tech',\n",
       " '.',\n",
       " 'merges',\n",
       " 'two',\n",
       " 'concepts',\n",
       " 'from',\n",
       " 'two',\n",
       " 'different',\n",
       " 'fields.Last',\n",
       " 'but',\n",
       " 'not',\n",
       " 'the',\n",
       " 'least',\n",
       " 'here',\n",
       " '’',\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'Stemming-',\n",
       " 'It',\n",
       " 'is',\n",
       " 'very',\n",
       " 'essential',\n",
       " 'to',\n",
       " 'pythonly',\n",
       " 'while',\n",
       " 'you',\n",
       " 'are',\n",
       " 'pythoning',\n",
       " 'with',\n",
       " 'the',\n",
       " 'Python',\n",
       " 'language',\n",
       " '.',\n",
       " 'All',\n",
       " 'Pythonistas',\n",
       " 'must',\n",
       " 'have',\n",
       " 'pythoned',\n",
       " 'badly',\n",
       " 'at',\n",
       " 'least',\n",
       " 'once',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.corpus import stopwords \n",
    "token_Q2b = word_tokenize(Q2_input)\n",
    "token_Q2b\n",
    "\n",
    "#swords = stopwords.words('english')\n",
    "#filtered_words = []\n",
    "#filtered_words = [w for w in token_Q2b if w not in swords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hello', 'NNP'), ('Mr.', 'NNP'), ('Timmy', 'NNP'), ('Following', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('story', 'NN'), ('of', 'IN'), ('a', 'DT'), ('girly', 'JJ'), ('girl', 'NN'), ('named', 'VBN'), ('as', 'IN'), (\"KATY'18\", 'NNP'), ('.', '.'), ('Working', 'NNP'), ('as', 'IN'), ('a', 'DT'), ('``', '``'), ('Jr', 'NNP'), ('.', '.'), ('Consultant', 'NNP'), (\"''\", \"''\"), ('with', 'IN'), ('TIBCO', 'NNP'), ('Software', 'NNP'), ('Inc.', 'NNP'), (',', ','), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('Integration', 'NNP'), ('along', 'IN'), ('with', 'IN'), ('T.I.B.C.O', 'NNP'), ('.', '.'), ('BusinessWorks', 'NNP'), ('proved', 'VBD'), ('to', 'TO'), ('be', 'VB'), ('great', 'JJ'), ('experience', 'NN'), ('to', 'TO'), ('me', 'PRP'), ('as', 'IN'), ('I', 'PRP'), ('had', 'VBD'), ('the', 'DT'), ('privilege', 'NN'), ('to', 'TO'), ('work', 'VB'), ('most', 'JJS'), ('complex', 'JJ'), ('part', 'NN'), ('of', 'IN'), ('any', 'DT'), ('application', 'NN'), (',', ','), ('i.e', 'NN'), ('Middleware', 'NNP'), ('.', '.'), ('Snow', 'NNP'), ('comprises', 'VBZ'), ('individual', 'JJ'), ('ice', 'NN'), ('crystals', 'NNS'), ('that', 'WDT'), ('grow', 'VBP'), ('while', 'IN'), ('suspended', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('atmosphere—usually', 'RB'), ('within', 'IN'), ('clouds—and', 'NN'), ('then', 'RB'), ('fall', 'NN'), (',', ','), ('accumulating', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('ground', 'NN'), ('where', 'WRB'), ('they', 'PRP'), ('undergo', 'VBP'), ('further', 'JJ'), ('changes', 'NNS'), ('.', '.'), ('As', 'IN'), ('a', 'DT'), ('child', 'NN'), (',', ','), ('I', 'PRP'), ('loved', 'VBD'), ('sitting', 'VBG'), ('on', 'IN'), ('my', 'PRP$'), ('grandfather', 'NN'), (\"'s\", 'POS'), ('lap', 'NN'), ('while', 'IN'), ('he', 'PRP'), ('read', 'VB'), ('me', 'PRP'), ('stories.As', 'VB'), ('a', 'DT'), ('child', 'NN'), (',', ','), ('I', 'PRP'), ('was', 'VBD'), ('blissfully', 'RB'), ('unaware', 'JJ'), ('that', 'RB'), (',', ','), ('as', 'IN'), ('I', 'PRP'), ('listened', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('stories', 'NNS'), (',', ','), ('I', 'PRP'), ('was', 'VBD'), ('also', 'RB'), ('learning', 'VBG'), ('new', 'JJ'), ('words', 'NNS'), ('and', 'CC'), ('ways', 'NNS'), ('in', 'IN'), ('which', 'WDT'), ('those', 'DT'), ('new', 'JJ'), ('words', 'NNS'), ('combined', 'VBN'), ('to', 'TO'), ('communicate', 'VB'), ('ideas', 'NNS'), (',', ','), ('life', 'NN'), ('lessons.A', 'RB'), ('good', 'JJ'), ('Europe', 'NNP'), (\"'s\", 'POS'), ('story', 'NN'), ('encourages', 'VBZ'), ('us', 'PRP'), ('to', 'TO'), ('turn', 'VB'), ('the', 'DT'), ('next', 'JJ'), ('page', 'NN'), ('and', 'CC'), ('read', 'VB'), ('more', 'JJR'), ('.', '.'), ('We', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('find', 'VB'), ('out', 'RP'), ('what', 'WP'), ('happens', 'VBZ'), ('next', 'JJ'), ('and', 'CC'), ('what', 'WP'), ('the', 'DT'), ('main', 'JJ'), ('characters', 'NNS'), ('do', 'VBP'), ('and', 'CC'), ('what', 'WP'), ('they', 'PRP'), ('say', 'VBP'), ('to', 'TO'), ('each', 'DT'), ('other', 'JJ'), ('.', '.'), ('We', 'PRP'), ('may', 'MD'), ('feel', 'VB'), ('excited', 'JJ'), (',', ','), ('sad', 'JJ'), (',', ','), ('afraid', 'JJ'), (',', ','), ('angry', 'JJ'), ('or', 'CC'), ('really', 'RB'), ('happy', 'JJ'), ('.', '.'), ('Do', 'VBP'), ('you', 'PRP'), ('think', 'VB'), ('that', 'IN'), ('with', 'IN'), ('Impact', 'NNP'), ('Wrestling', 'VBG'), ('moving', 'VBG'), ('to', 'TO'), ('AXS', 'NNP'), (',', ','), ('a', 'DT'), ('lot', 'NN'), ('more', 'JJR'), ('eyes', 'NNS'), ('will', 'MD'), ('be', 'VB'), ('on', 'IN'), ('the', 'DT'), ('product', 'NN'), ('?', '.'), ('This', 'DT'), ('week', 'NN'), (',', ','), ('as', 'RB'), ('good', 'JJ'), ('as', 'IN'), ('the', 'DT'), ('show', 'NN'), ('was', 'VBD'), (',', ','), ('there', 'EX'), ('were', 'VBD'), ('only', 'RB'), ('3,500', 'CD'), ('people', 'NNS'), ('watching', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('Twitch', 'NNP'), ('stream', 'NN'), (',', ','), ('and', 'CC'), ('that', 'DT'), ('was', 'VBD'), ('the', 'DT'), ('upper', 'JJ'), ('limit', 'NN'), ('number', 'NN'), ('during', 'IN'), ('the', 'DT'), ('stream', 'NN'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('why', 'WRB'), ('the', 'DT'), ('words', 'NNS'), ('that', 'WDT'), ('relate', 'VBP'), ('a', 'DT'), ('story', 'NN'), (\"'s\", 'POS'), ('events', 'NNS'), (',', ','), ('conversations', 'NNS'), ('are', 'VBP'), ('processed', 'VBN'), ('in', 'IN'), ('this', 'DT'), ('deeper', 'JJ'), ('way.In', 'NN'), ('fact', 'NN'), (',', ','), ('cultures', 'VBZ'), ('all', 'DT'), ('around', 'IN'), ('the', 'DT'), ('world', 'NN'), ('have', 'VBP'), ('always', 'RB'), ('used', 'VBN'), ('storytelling', 'VBG'), ('to', 'TO'), ('pass', 'VB'), ('knowledge', 'NN'), ('from', 'IN'), ('one', 'CD'), ('generation', 'NN'), ('to', 'TO'), ('another.The', 'VB'), ('tech', 'NN'), ('.', '.'), ('merges', 'NNS'), ('two', 'CD'), ('concepts', 'NNS'), ('from', 'IN'), ('two', 'CD'), ('different', 'JJ'), ('fields.Last', 'NNS'), ('but', 'CC'), ('not', 'RB'), ('the', 'DT'), ('least', 'JJS'), ('here', 'RB'), ('’', 'JJ'), ('s', 'VBP'), ('an', 'DT'), ('example', 'NN'), ('of', 'IN'), ('Stemming-', 'NNP'), ('It', 'PRP'), ('is', 'VBZ'), ('very', 'RB'), ('essential', 'JJ'), ('to', 'TO'), ('pythonly', 'RB'), ('while', 'IN'), ('you', 'PRP'), ('are', 'VBP'), ('pythoning', 'VBG'), ('with', 'IN'), ('the', 'DT'), ('Python', 'NNP'), ('language', 'NN'), ('.', '.'), ('All', 'DT'), ('Pythonistas', 'NNP'), ('must', 'MD'), ('have', 'VB'), ('pythoned', 'VBN'), ('badly', 'RB'), ('at', 'IN'), ('least', 'JJS'), ('once', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = pos_tag(token_Q2b)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tags(tag):\n",
    "    if tag == 'VBZ' or tag == 'VBN'or tag == 'VBD'or tag == 'VB'or tag == 'VBG'or tag == 'VBP':\n",
    "        return 'v'\n",
    "    elif tag == 'NN' or tag == 'NNP' or tag == 'NNS':\n",
    "        return 'n'\n",
    "    #elif tag == 'RB' or tag == 'RBR' or tag == 'RBS':\n",
    "     #   return 'p'\n",
    "    elif tag.startswith('j') or tag.startswith('J') :\n",
    "        return 'a'\n",
    "    elif tag.startswith('r') or tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello n ,\n",
      "Mr. n ,\n",
      "Timmy n ,\n",
      "Following n ,\n",
      "be v ,\n",
      "a n ,\n",
      "story n ,\n",
      "of n ,\n",
      "a n ,\n",
      "girly a ,\n",
      "girl n ,\n",
      "name v ,\n",
      "a n ,\n",
      "KATY'18 n ,\n",
      ". n ,\n",
      "Working n ,\n",
      "a n ,\n",
      "a n ,\n",
      "`` n ,\n",
      "Jr n ,\n",
      ". n ,\n",
      "Consultant n ,\n",
      "'' n ,\n",
      "with n ,\n",
      "TIBCO n ,\n",
      "Software n ,\n",
      "Inc. n ,\n",
      ", n ,\n",
      "in n ,\n",
      "the n ,\n",
      "field n ,\n",
      "of n ,\n",
      "Integration n ,\n",
      "along n ,\n",
      "with n ,\n",
      "T.I.B.C.O n ,\n",
      ". n ,\n",
      "BusinessWorks n ,\n",
      "prove v ,\n",
      "to n ,\n",
      "be v ,\n",
      "great a ,\n",
      "experience n ,\n",
      "to n ,\n",
      "me n ,\n",
      "a n ,\n",
      "I n ,\n",
      "have v ,\n",
      "the n ,\n",
      "privilege n ,\n",
      "to n ,\n",
      "work v ,\n",
      "most a ,\n",
      "complex a ,\n",
      "part n ,\n",
      "of n ,\n",
      "any n ,\n",
      "application n ,\n",
      ", n ,\n",
      "i.e n ,\n",
      "Middleware n ,\n",
      ". n ,\n",
      "Snow n ,\n",
      "comprise v ,\n",
      "individual a ,\n",
      "ice n ,\n",
      "crystal n ,\n",
      "that n ,\n",
      "grow v ,\n",
      "while n ,\n",
      "suspend v ,\n",
      "in n ,\n",
      "the n ,\n",
      "atmosphere—usually r ,\n",
      "within n ,\n",
      "clouds—and n ,\n",
      "then r ,\n",
      "fall n ,\n",
      ", n ,\n",
      "accumulate v ,\n",
      "on n ,\n",
      "the n ,\n",
      "ground n ,\n",
      "where n ,\n",
      "they n ,\n",
      "undergo v ,\n",
      "further a ,\n",
      "change n ,\n",
      ". n ,\n",
      "As n ,\n",
      "a n ,\n",
      "child n ,\n",
      ", n ,\n",
      "I n ,\n",
      "love v ,\n",
      "sit v ,\n",
      "on n ,\n",
      "my n ,\n",
      "grandfather n ,\n",
      "'s n ,\n",
      "lap n ,\n",
      "while n ,\n",
      "he n ,\n",
      "read v ,\n",
      "me n ,\n",
      "stories.As v ,\n",
      "a n ,\n",
      "child n ,\n",
      ", n ,\n",
      "I n ,\n",
      "be v ,\n",
      "blissfully r ,\n",
      "unaware a ,\n",
      "that r ,\n",
      ", n ,\n",
      "a n ,\n",
      "I n ,\n",
      "listen v ,\n",
      "to n ,\n",
      "the n ,\n",
      "story n ,\n",
      ", n ,\n",
      "I n ,\n",
      "be v ,\n",
      "also r ,\n",
      "learn v ,\n",
      "new a ,\n",
      "word n ,\n",
      "and n ,\n",
      "way n ,\n",
      "in n ,\n",
      "which n ,\n",
      "those n ,\n",
      "new a ,\n",
      "word n ,\n",
      "combine v ,\n",
      "to n ,\n",
      "communicate v ,\n",
      "idea n ,\n",
      ", n ,\n",
      "life n ,\n",
      "lessons.A r ,\n",
      "good a ,\n",
      "Europe n ,\n",
      "'s n ,\n",
      "story n ,\n",
      "encourage v ,\n",
      "u n ,\n",
      "to n ,\n",
      "turn v ,\n",
      "the n ,\n",
      "next a ,\n",
      "page n ,\n",
      "and n ,\n",
      "read v ,\n",
      "more a ,\n",
      ". n ,\n",
      "We n ,\n",
      "want v ,\n",
      "to n ,\n",
      "find v ,\n",
      "out r ,\n",
      "what n ,\n",
      "happen v ,\n",
      "next a ,\n",
      "and n ,\n",
      "what n ,\n",
      "the n ,\n",
      "main a ,\n",
      "character n ,\n",
      "do v ,\n",
      "and n ,\n",
      "what n ,\n",
      "they n ,\n",
      "say v ,\n",
      "to n ,\n",
      "each n ,\n",
      "other a ,\n",
      ". n ,\n",
      "We n ,\n",
      "may n ,\n",
      "feel v ,\n",
      "excited a ,\n",
      ", n ,\n",
      "sad a ,\n",
      ", n ,\n",
      "afraid a ,\n",
      ", n ,\n",
      "angry a ,\n",
      "or n ,\n",
      "really r ,\n",
      "happy a ,\n",
      ". n ,\n",
      "Do v ,\n",
      "you n ,\n",
      "think v ,\n",
      "that n ,\n",
      "with n ,\n",
      "Impact n ,\n",
      "Wrestling v ,\n",
      "move v ,\n",
      "to n ,\n",
      "AXS n ,\n",
      ", n ,\n",
      "a n ,\n",
      "lot n ,\n",
      "more a ,\n",
      "eye n ,\n",
      "will n ,\n",
      "be v ,\n",
      "on n ,\n",
      "the n ,\n",
      "product n ,\n",
      "? n ,\n",
      "This n ,\n",
      "week n ,\n",
      ", n ,\n",
      "as r ,\n",
      "good a ,\n",
      "a n ,\n",
      "the n ,\n",
      "show n ,\n",
      "be v ,\n",
      ", n ,\n",
      "there n ,\n",
      "be v ,\n",
      "only r ,\n",
      "3,500 n ,\n",
      "people n ,\n",
      "watch v ,\n",
      "on n ,\n",
      "the n ,\n",
      "Twitch n ,\n",
      "stream n ,\n",
      ", n ,\n",
      "and n ,\n",
      "that n ,\n",
      "be v ,\n",
      "the n ,\n",
      "upper a ,\n",
      "limit n ,\n",
      "number n ,\n",
      "during n ,\n",
      "the n ,\n",
      "stream n ,\n",
      ". n ,\n",
      "This n ,\n",
      "be v ,\n",
      "why n ,\n",
      "the n ,\n",
      "word n ,\n",
      "that n ,\n",
      "relate v ,\n",
      "a n ,\n",
      "story n ,\n",
      "'s n ,\n",
      "event n ,\n",
      ", n ,\n",
      "conversation n ,\n",
      "be v ,\n",
      "process v ,\n",
      "in n ,\n",
      "this n ,\n",
      "deep a ,\n",
      "way.In n ,\n",
      "fact n ,\n",
      ", n ,\n",
      "culture v ,\n",
      "all n ,\n",
      "around n ,\n",
      "the n ,\n",
      "world n ,\n",
      "have v ,\n",
      "always r ,\n",
      "use v ,\n",
      "storytelling v ,\n",
      "to n ,\n",
      "pass v ,\n",
      "knowledge n ,\n",
      "from n ,\n",
      "one n ,\n",
      "generation n ,\n",
      "to n ,\n",
      "another.The v ,\n",
      "tech n ,\n",
      ". n ,\n",
      "merges n ,\n",
      "two n ,\n",
      "concept n ,\n",
      "from n ,\n",
      "two n ,\n",
      "different a ,\n",
      "fields.Last n ,\n",
      "but n ,\n",
      "not r ,\n",
      "the n ,\n",
      "least a ,\n",
      "here r ,\n",
      "’ a ,\n",
      "s v ,\n",
      "an n ,\n",
      "example n ,\n",
      "of n ,\n",
      "Stemming- n ,\n",
      "It n ,\n",
      "be v ,\n",
      "very r ,\n",
      "essential a ,\n",
      "to n ,\n",
      "pythonly r ,\n",
      "while n ,\n",
      "you n ,\n",
      "be v ,\n",
      "pythoning v ,\n",
      "with n ,\n",
      "the n ,\n",
      "Python n ,\n",
      "language n ,\n",
      ". n ,\n",
      "All n ,\n",
      "Pythonistas n ,\n",
      "must n ,\n",
      "have v ,\n",
      "pythoned v ,\n",
      "badly r ,\n",
      "at n ,\n",
      "least a ,\n",
      "once r ,\n",
      ". n ,\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "for ele in pos_tags:\n",
    "    new_tag = convert_tags(ele[1])\n",
    "    #print([ele[0],new_tag])\n",
    "    lemm = wnl.lemmatize(ele[0],new_tag)\n",
    "    print(lemm,new_tag,',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
